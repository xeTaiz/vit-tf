{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser('Convert Nifti to .pt')\n",
    "    parser.add_argument('file_path', type=str, help='path to volume nifti')\n",
    "    parser.add_argument('mask_path', type=str, help='path to mask nifti')\n",
    "    args = parser.parse_args()\n",
    "    # define the paths to the images.\n",
    "    file_path = args.file_path\n",
    "    mask_path = args.mask_path\n",
    "    save_path = Path(file_path).parent\n",
    "\n",
    "    # loading the image\n",
    "    img = nib.load(file_path)\n",
    "    # extract the img.\n",
    "    img = img.get_fdata()\n",
    "    img = img.transpose(2, 0, 1)\n",
    "\n",
    "    # loading the mask\n",
    "    if mask_path != \"\":\n",
    "        mask = nib.load(mask_path)\n",
    "        # extracting the mask. Mostly contains a volume with classes encoded as integer.\n",
    "        # So e.g. 0 is Background and 1 is target.\n",
    "        mask = mask.get_fdata()\n",
    "        mask = mask.transpose(2, 0, 1)\n",
    "\n",
    "    # convert the numpy array to tensor.\n",
    "    img = torch.from_numpy(img)\n",
    "\n",
    "    # change to fp16 to reduce the size.\n",
    "    # This step is not necessary and can be also removed,\n",
    "    # but could help with training on machines with not alot of VRAM.\n",
    "    img = img.to(torch.float16)\n",
    "\n",
    "    # create the path and name for the file to save.\n",
    "    path = os.path.join(save_path,\n",
    "                        file_path.split(\"/\")[-1].split(\".\")[0] + \".pt\")\n",
    "    Path(\"data\").mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "    # save the volumes as torch files.\n",
    "    if mask_path != \"\":\n",
    "        # applying the save processing to the images.\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.to(torch.int16)\n",
    "        # saving the image with mask and it at the specified path.\n",
    "        torch.save({\"vol\": img, \"mask\": mask, \"id\": 1}, path)\n",
    "    else:\n",
    "        # saving the image with mask and it at the specified path.\n",
    "        torch.save({\"vol\": img, \"id\": 1}, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = Path('/run/media/dome/Data/data/Volumes/CT-ORG')\n",
    "vol_paths = zip(sorted(dir.rglob('volume*')), sorted(dir.rglob('label*')))\n",
    "lbls = ['background', 'liver', 'bladder', 'lung', 'kidney', 'bone', 'brain']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vp, lp in vol_paths:\n",
    "    vol_np = nib.load(vp).get_fdata()\n",
    "    vol = torch.from_numpy(vol_np).half()\n",
    "\n",
    "    mask_np = nib.load(lp).get_fdata().round()\n",
    "    mask = torch.from_numpy(mask_np).to(torch.uint8)\n",
    "\n",
    "    vnum = int(vp.stem.split('-')[-1].split('.')[0])\n",
    "    lnum = int(lp.stem.split('-')[-1].split('.')[0])\n",
    "    assert vnum == lnum\n",
    "\n",
    "    torch.save({\n",
    "        'vol': vol,\n",
    "        'mask': mask,\n",
    "        'labels': lbls\n",
    "    }, vp.parent / f'torch/volume_{vnum:03d}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ntf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17923edd6f645ccb8649f8250a3cd50f7ab4a9998899231269fb5f334170d723"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
